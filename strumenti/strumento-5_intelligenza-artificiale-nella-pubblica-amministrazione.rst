5. Strumento 5 - Intelligenza Artificiale nella Pubblica Amministrazione
========================================================================

*Versione 1.0 del 21/12/2023*

-  Obiettivo

   Il documento fornisce indicazioni operative per l'adozione
   dell'Intelligenza Artificiale basate sull'esperienza pratica per
   l'implementazione delle tecnologie di IA nella Pubblica Amministrazione.

-  Destinatari

   Pubbliche amministrazioni ed enti strumentali che erogano servizi
   digitali per conto delle pubbliche amministrazioni.

-  Crediti

   Il documento è stato redatto con il contributo di Consorzio
   Interuniversitario Nazionale per l'Informatica (CINI), INAIL, ISTAT,
   INPS.

5.1. AI Act: un approccio basato sul rischio
--------------------------------------------

L'AI Act intende stabilire obblighi per fornitori e utenti per mitigare
i rischi legati all'utilizzo dell'IA. I rischi sono classificati in
quattro diversi livelli: rischio inaccettabile (divieto), rischio
elevato, rischio limitato e rischio minimo.

A titolo informativo si riportano di seguito i profili di rischio
previsti dal testo dell'AI Act emendato il 14 giugno 2023. In attesa
dell'emanazione del regolamento tale classificazione può essere
considerata una utile guida per le pubbliche amministrazioni che hanno
intenzione di dotarsi di sistemi di intelligenza artificiale.

L'AI Act considera una minaccia per le persone e quindi vieta i sistemi
di intelligenza artificiale a rischio inaccettabile. Essi comprendono:

-  Manipolazione cognitiva comportamentale di persone o di specifici
   gruppi vulnerabili: ad esempio giocattoli ad attivazione vocale che
   incoraggiano i bambini a comportamenti pericolosi;

-  Social scoring: classificazione delle persone in base al
   comportamento, allo status socio-economico o alle caratteristiche
   personali.

-  Sistemi di identificazione biometrica in tempo reale e a distanza,
   come il riconoscimento facciale.

Possono essere ammesse alcune eccezioni. Ad esempio, i sistemi di
identificazione biometrica "ex-post", in cui l'identificazione avviene
dopo un ritardo significativo, saranno consentiti per perseguire reati
gravi, ma solo dopo l'approvazione delle autorità giudiziarie.

L'AI Act considera ad alto rischio i sistemi di IA che possono avere
conseguenze negativamente sulla sicurezza o sui diritti fondamentali
dell'uomo. La proposta di regolamento individua due categorie di sistemi
ad alto rischio:

1. sistemi di intelligenza artificiale utilizzati in prodotti che
   rientrano nella legislazione dell'UE sulla sicurezza dei prodotti. Si
   tratta di giocattoli, velivoli, automobili, dispositivi medici e
   ascensori.

2. sistemi di intelligenza artificiale che rientrano in otto aree
   specifiche e che dovranno essere registrati in un database dell'UE:

   -  identificazione biometrica e categorizzazione delle persone fisiche

   -  gestione e funzionamento di infrastrutture critiche

   -  istruzione e formazione professionale

   -  occupazione, gestione dei lavoratori e accesso al lavoro autonomo

   -  accesso e fruizione di servizi privati essenziali e di servizi e
      prestazioni pubbliche

   -  pubblica sicurezza

   -  migrazione, asilo e controllo delle frontiere

   -  interpretazione giuridica e applicazione della legge.

Tutti i sistemi di IA ad alto rischio dovranno essere valutati sia prima
di essere immessi sul mercato sia durante il loro ciclo di vita.

Nel corso dell'iter di definizione del regolamento sono stati anche
introdotti alcuni requisiti minimi di trasparenza per l'IA generativa,
che dovrebbero:

-  rivelare che il contenuto è stato generato dall'IA;

-  progettare il modello per evitare che generi contenuti illegali;

-  pubblicare riepiloghi dei dati protetti da diritto di autore e
   utilizzati per l'addestramento.

Secondo l'AI Act i sistemi di IA a rischio limitato dovrebbero
soddisfare requisiti minimi di trasparenza che consentano agli utenti di
prendere decisioni informate. Dopo aver interagito con le applicazioni,
l'utente può decidere se continuare a utilizzarle. In generale, gli
utenti devono essere informati quando interagiscono con l'IA. Ciò
include i sistemi di IA che generano o manipolano contenuti di immagini,
audio o video.

5.2. La visione del Laboratorio Artificial Intelligence and Intelligent Systems (AIIS) del CINI
-----------------------------------------------------------------------------------------------

Un'adozione efficace e conforme alla normativa di strumenti di
Intelligenza Artificiale (AI) all'interno della Pubblica Amministrazione
(PA) richiede un'attenta navigazione nel panorama legislativo corrente e
una previsione strategica delle evoluzioni future in questo ambito.

Il contesto normativo attuale mostra un crescente interesse e una serie
di iniziative di regolamentazione dell'AI ancora in divenire. Con
l'avvento di tecnologie sempre più avanzate, si rende necessario un
quadro normativo che ne guidi l'uso responsabile e etico.

Normative come l'imminente AI Act, e il GDPR (*General Data Protection
Regulation*), rappresentano elementi imprescindibili in questo percorso,
ponendo delle basi per la gestione dei dati e l'uso delle tecnologie AI.

Strategicamente, l'adozione dell'AI nella PA deve essere allineata con
gli obiettivi a lungo termine dell'amministrazione digitale, che
includono la digitalizzazione dei servizi, l'aumento dell'efficienza
amministrativa e la promozione di una governance trasparente e
accessibile. L'AI può giocare un ruolo cruciale in queste aree,
migliorando la capacità di analisi dei dati, automatizzando processi e
offrendo nuovi servizi ai cittadini. Per raggiungere questi risultati,
la PA deve garantire che i sistemi di AI adottati siano affidabili,
controllati da apposite procedure di gestione del rischio, privi di
implicazioni etiche e sociali negative.

5.3. Possibili obiettivi
------------------------

Tenuto conto delle incertezze e della rapida evoluzione del contesto,
nel breve periodo occorre partire da una fase di acquisizione
sistematica di conoscenze che poi dovrà essere seguita negli anni
successivi da un approccio operativo. In questa ottica, vengono
individuati tre obiettivi principali.

5.3.1. Acquisizione di conoscenze e strumenti per l'analisi del rischio nell'adozione di strumenti di AI
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

L'acquisizione di conoscenze e strumenti per l'analisi del rischio
nell'adozione di strumenti di Intelligenza Artificiale (AI) è un
pilastro fondamentale per la Pubblica Amministrazione nel contesto
attuale, dove l'AI Act e altre normative emergenti pongono l'accento
sulla gestione dei rischi associati all'utilizzo dell'AI. Questo impegno
si concentra non solo sulla comprensione dei potenziali pericoli, ma
anche sulle modalità di interazione con questi sistemi avanzati,
riconoscendo che il carattere dei rischi può variare significativamente
a seconda delle specifiche applicazioni dell'AI.

L'analisi del rischio nell'AI, in linea con le direttive dell'AI Act,
prevede un'attenta valutazione che va oltre la semplice identificazione
delle criticità. Questo processo richiede una comprensione approfondita
delle diverse categorie di rischio stabilite dalla normativa, che a loro
volta implicano diversi livelli di controllo e monitoraggio. L'essenza
di questo approccio risiede nel riconoscere che ogni applicazione
dell'AI possiede caratteristiche uniche e, di conseguenza, richiede una
strategia su misura per gestire i rischi ad essa associati.

Un elemento chiave per il raggiungimento di questo obiettivo è la
formazione e l'aggiornamento continuo delle competenze all'interno delle
amministrazioni pubbliche. Ciò implica non solo dotare i dipendenti
delle conoscenze tecniche necessarie per comprendere e gestire i rischi
dell'AI, ma anche sviluppare una cultura organizzativa che promuova la
consapevolezza e la responsabilità nei confronti di questi nuovi sistemi
tecnologici. In questo senso, l'analisi del rischio diventa un processo
dinamico, che evolve con il progresso tecnologico e l'accumulo di nuove
esperienze e conoscenze nel campo dell'AI.

5.3.2. Acquisizione di conoscenze sui principali standard internazionali applicabili a prodotti e servizi basati su AI
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

L'AI è un campo in rapida evoluzione, e con esso, anche gli standard
internazionali che ne governano l'uso. È fondamentale che le
amministrazioni siano consapevoli di questi standard per assicurare che
i prodotti e i servizi che adottano o sviluppano siano ad essi conformi.
In particolare, gli standard su AI del CEN-CENELEC, l'organismo europeo
di standardizzazione, specificheranno i criteri di conformità, anche in
relazione all'AI Act.

Inoltre, è fondamentale la conoscenza anche degli standard
internazionali come ISO/IEC 20546 (*Big Data - Overview and Vocabulary*)
e ISO/IEC 22989 (*AI - Artificial Intelligence Concepts and
Terminology*). L'attuazione di procedure di valutazione e di revisione
standardizzate sono elementi imprescindibili per assicurare che le
soluzioni AI rispettino gli standard internazionali e siano eticamente
responsabili.

5.3.3. Analisi e gestione dei dati da utilizzare in applicazioni basate su AI
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

I dati rappresentano l'elemento centrale per la realizzazione di
applicazioni basate su metodi di apprendimento automatico. Per ottenere
strumenti che rispondano alle esigenze e la cui introduzione sia sicura
ed affidabile sia sotto il profilo strettamente tecnico, che sotto il
profilo sociale, i dati che alimentano il sistema di AI devono
soddisfare dei requisiti di qualità.

Conoscere tali requisiti è un presupposto fondamentale per affrontare lo
sviluppo di sistemi AI. Diversi sono gli aspetti da considerare per
garantire la qualità dei dati, che sono fortemente legati al contesto
applicativo e pertanto richiedono da parte delle PA un approfondimento
che consenta di calare, nel proprio dominio operativo, indicazioni di
carattere generale come Analisi di Rappresentatività dei Dati,
Prevenzione e Identificazione dei Bias, Protezione della Privacy, ecc.
Queste indicazioni si aggiungono alle indicazioni da seguire per
qualsiasi applicazione informatica e che includono, tra l'altro, la
standardizzazione della raccolta dati, la loro affidabilità e coerenza,
e la verifica e pulizia, ottenuta attraverso processi volti ad eliminare
errori e inesattezze.

5.4. Suggerimenti per le azioni dirette alle PA
-----------------------------------------------

5.4.1. Predisposizione di strumenti per l'analisi del rischio
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

In un'era dove l'Intelligenza Artificiale (AI) si sta rapidamente
integrando nelle strutture della Pubblica Amministrazione (PA), la
predisposizione di strumenti efficaci per l'analisi del rischio diventa
un aspetto cruciale. AGID, DTD e altri soggetti istituzionali sono
chiamati a svolgere un ruolo fondamentale in questo processo, fornendo
alle amministrazioni gli strumenti necessari per navigare con sicurezza
nel complesso panorama dell'AI.

Questa missione richiede non solo la creazione di risorse adatte, ma
anche l'attuazione di una formazione mirata e di un supporto continuo.
La sfida sta nel bilanciare innovazione e sicurezza, garantendo che
l'adozione dell'AI nella PA avvenga in un ambiente controllato e
consapevole dei potenziali rischi e benefici.

Alcune possibili azioni includono:

-  **Creazione di strumenti per l'analisi del rischio**: tali strumenti
   dovranno includere modelli, linee guida e best practices. Gli
   strumenti in questione devono essere adattabili alle esigenze di
   diverse dimensioni e tipologie di PA.

-  **Formazione e Supporto**: Sulla base di questi strumenti, offrire
   formazione e supporto tecnico alle amministrazioni per un loro uso
   efficace.

-  **Aggiornamento Continuo**: Mantenere gli strumenti aggiornati con le
   ultime ricerche e sviluppi nel campo dell'AI.

5.4.2. Sviluppo di metodologie e procedure di valutazione per applicazioni AI
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

L'implementazione di metodologie e procedure di valutazione per le
applicazioni AI rappresenta un tassello fondamentale nella strategia di
digitalizzazione della PA. A seguito dell'introduzione dell'AI Act, si
dovrà assicurare che le PA siano pienamente equipaggiate per valutare e
gestire le applicazioni AI in conformità con le normative vigenti.
Questo compito richiede una profonda comprensione dei principi etici e
legali che governano l'uso dell'AI, oltre alla capacità di tradurre
queste conoscenze in pratiche operative concrete.

L'obiettivo è di creare un ambiente in cui l'AI possa essere utilizzata
in modo efficace e responsabile, massimizzando i benefici per la società
pur rispettando rigorosi standard di sicurezza e etica.

Alcune possibili azioni includono:

-  Guida sull'AI Act: Fornire una guida chiara e dettagliata
   sull'applicazione dell'AI Act, aiutando le amministrazioni a
   comprendere e aderire ai requisiti normativi.

-  Workshop e Seminari: Organizzare incontri formativi per discutere
   l'interpretazione e l'implementazione dell'AI Act ai diversi settori
   della PA.

-  Strumenti di Autovalutazione: Creare strumenti che permettano alle
   amministrazioni di condurre valutazioni interne.

5.4.3. Assicurare Linee Guida sulla raccolta e il trattamento di dati finalizzati all'utilizzo in sistemi AI
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Creare e implementare un insieme di linee guida robuste per la raccolta
e il trattamento dei dati all'interno della Pubblica Amministrazione.
Queste linee guida dovranno mirare a garantire che i dati utilizzati
come training per sistemi di Intelligenza Artificiale (AI) siano di alta
qualità, privi di bias, rappresentativi della popolazione e trattati nel
pieno rispetto della privacy.

5.4.4. Progettazione e adozione di un piano di competenze per l'AI
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

- **Mappatura delle competenze necessarie**

   -  Eseguire una dettagliata analisi delle competenze necessarie per
      implementare e gestire efficacemente l'AI nella PA.

   -  Identificare specifiche abilità tecniche, gestionali ed etiche
      richieste.

-  **Differenziazione tra competenze in-house e esternalizzate**

   -  Valutare quali competenze possono essere sviluppate internamente e
      quali richiedono l'apporto di esperti esterni.

   -  Stabilire un equilibrio tra le risorse interne e l'outsourcing per
      ottimizzare l'efficienza e l'efficacia.

-  **Messa in atto di un programma di upskilling**

   -  Implementare programmi formativi per aggiornare le competenze del
      personale esistente.

   -  Organizzare workshop, corsi di formazione e partnership con
      istituzioni accademiche e aziende del settore.

5.4.4.1. Competenze chiave da coprire:
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

-  Innovation manager esperto di AI: professionista con visione
   strategica e competenze tecniche per guidare l'introduzione dell'AI.

-  Ethics officer: specialista incaricato di assicurare che l'uso
   dell'AI sia conforme ai principi etici e legali.

-  Esperto di apprendimento automatico e Intelligenza Artificiale:
   tecnico qualificato per lo sviluppo e la gestione di soluzioni basate
   su AI.

-  Esperto di dati: professionista focalizzato sulla gestione, analisi e
   sicurezza dei dati.

5.4.5. Progettazione e adozione di un piano dei fabbisogni
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

-  Individuazione dei servizi e dei processi da valorizzare con sistemi
   di AI

   -  Identificare aree specifiche dove l'AI può migliorare
      l'efficienza, la precisione e l'efficacia dei servizi pubblici.

   -  Priorizzare i processi che possono trarre maggior beneficio
      dall'integrazione con l'AI.

-  Individuazione dei dati e verifica della qualità

   -  Selezionare set di dati pertinenti per le applicazioni AI.

   -  Assicurare che i dati siano di alta qualità, rappresentativi e
      privi di bias.

-  Individuazione delle implicazioni etiche e legali

   -  Analizzare le implicazioni etiche e legali dell'uso dell'AI nei
      servizi pubblici.

   -  Assicurare che ogni implementazione sia in linea con le normative
      vigenti e rispetti i principi etici fondamentali.

5.5. L'esperienza di INAIL
--------------------------

In un contesto in continua evoluzione, l'adozione di tecnologie basate
sull'intelligenza Artificiale da parte dell'Istituto Nazionale contro
gli Infortuni sul Lavoro (INAIL) si presenta come un obiettivo
strategico di primaria importanza sia per migliorare la propria
organizzazione interna che per erogare servizi avanzati ai cittadini.

In questo capitolo sono analizzate come INAIL le sfide, le opportunità e
i benefici derivanti dai progetti di IA dell'INAIL, quali siano le
prospettive future in questo ambito e i progetti attualmente in corso.
Nel contesto dell'organizzazione e dei processi, INAIL si è dotata di un
modello maturo di Open Innovation per gestire le innovazioni e i
cambiamenti che avverranno nei prossimi mesi, anche dal punto di vista
legislativo. L'introduzione dell'AI Act, infatti, comporterà adeguamenti
normativi per l'INAIL sia come fornitore che come utente di soluzioni
IA. Per questo è prevista l'integrazione di un framework di governance
dell'IA all'esistente quadro di governance del dato e la revisione di
processi e prassi già esistenti per garantire la conformità legale ed
etica lungo tutto il ciclo di vita delle soluzioni IA.

5.5.1. Il percorso di INAIL nel mondo dell'IA
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

L'Intelligenza Artificiale (IA) sta rivoluzionando il mondo grazie alla
rapida e immediata disponibilità di soluzioni che permettono di
automatizzare ed efficientare un'ampia gamma di processi. Anche INAIL ha
avviato da tempo un percorso di adozione di tali tecnologie, nell'ottica
di abilitare nuove opportunità e benefici.

Le soluzioni di IA dell'INAIL coprono una vasta gamma di ambiti e
settori, di conseguenza le scelte di applicazione dell'IA sono state
effettuate con una specifica coerenza strategica rispetto agli obiettivi
prefissati. Gli ambiti coperti variano quindi dall'assistenza virtuale
ad utenti esterni attraverso l'impiego di chatbot ad hoc, ai servizi di
monitoraggio e analisi dei ticket, a strumenti avanzati per la selezione
di pubblicazioni scientifiche e la raccolta automatica di dati
provenienti da repository specializzati. La presenza di applicativi
predittivi che analizzano dati su rischi e incidenti, inoltre,
sottolinea la chiara missione dell'INAIL nella promozione e
sensibilizzazione sui temi della sicurezza sul lavoro e del benessere
dei lavoratori. In generale, l'INAIL si è focalizzato sul valorizzare al
meglio il proprio patrimonio informativo potenziando le capacità di
analisi e ricerca sui dati e sviluppando di conseguenza soluzioni custom
mediante linguaggi come *Phyton*, in integrazione a prodotti di mercato.

Si riportano di seguito, aggregate in funzione dei principali benefici
per area di riferimento, le più significative attività progettuali in
corso.

1. **Miglioramento dell'Efficienza Operativa e Pianificazione**

   L'IA può automatizzare processi operativi complessi, migliorando
   l'efficienza nella gestione dei dati, nelle operazioni quotidiane e
   nelle pratiche amministrative. Ciò consente di risparmiare tempo e
   risorse, ridistribuendo le attività in modo più adeguato. In tale
   contesto, INAIL ha avviato numerosi progetti volti ad introdurre l'IA
   per migliorare l'operatività. Si citano l'utilizzo di sistemi
   analitico-predittivi per la definizione di un modello di *what-if
   analysis* focalizzato sulle politiche del personale e l'utilizzo di
   analoghi strumenti per la gestione del bilancio tecnico attuariale,
   mediante una soluzione che consente di produrre il bilancio di
   previsione dell'INAIL per un periodo futuro fino a 30-50-90 anni.

2. **Sensibilizzazione, formazione e analisi dei Dati per la Prevenzione
   degli Infortuni**

   L'analisi predittiva basata sull'IA può essere utilizzata per esaminare
   grandi dataset e identificare modelli che potrebbero prevedere
   potenziali rischi di infortuni. Questo può dunque contribuire a
   sviluppare strategie di sensibilizzazione, formazione e prevenzione più
   efficaci o interventi mirati in ambito; in tale ottica sono stati
   avviati progetti che prevedono l'adozione di sistemi cognitivi per
   l'analisi dei dati afferenti agli infortuni mortali, i quasi incidenti e
   gli infortuni su strada.

3. **Gestione delle Richieste e dei Reclami**

   Chatbot addestrati dall'IA attraverso tecniche di Machine Learning sono
   in fase di implementazione per gestire le richieste e i reclami degli
   utenti, fornendo loro risposte immediate e migliorandone l'esperienza
   complessiva; tali strumenti abilitano altresì la riqualificazione
   dell'attività del personale interno, favorendone la riallocazione verso
   attività a maggior valore aggiunto.

4. **Automazione nell'Elaborazione delle Prestazioni e nella gestione
   dei Bandi**

   L'IA viene utilizzata per automatizzare la gestione dei bandi e delle
   prestazioni, accelerando i processi e riducendo gli errori manuali. Si
   cita in tal senso l'utilizzo di sistemi cognitivi e di IA per facilitare
   ed efficientare i processi interni ed esterni delle procedure dei Bandi
   ISI attraverso l'implementazione di un Assistente Personale verso gli
   utenti, l'Analisi dei documenti amministrativi e tecnici ISI, e la
   classificazione documentale per fornire *alert* alle imprese in fase di
   caricamento.

5. **Analisi dei Dati Medici**

   L'IA può essere applicata all'analisi dei dati medici per migliorare la
   valutazione delle condizioni di salute dei lavoratori, contribuendo a
   una valutazione più accurata delle richieste di indennizzo. Per
   traguardare il beneficio sono in corso di sviluppo un modello di Machine
   Learning che supporta il medico nella valutazione del danno rispetto ai
   dati relativi all'infortunio, ed un sistema cognitivo per la ricerca di
   pareri simili secondo entità e concetti presenti nei referti. È inoltre
   attiva una progettualità legata all'utilizzo di sistemi cognitivi e di
   IA per la lavorazione dei pareri della Consulenza tecnica in materia di
   valutazione dei fattori di rischio correlati all'insorgenza e al
   riconoscimento delle malattie professionali.

6. **Rilevamento di Frodi**

   L'IA può essere impiegata per identificare modelli sospetti o anomalie
   nei dati, contribuendo alla prevenzione delle frodi legate alle
   richieste di indennizzo. Anche in questo caso l'INAIL ha avviato e
   completato, fra gli altri, un progetto per la revisione delle anomalie
   nel flusso di gestione delle pratiche, attraverso suggerimenti
   intelligenti via Machine Learning, allo scopo di identificare e
   prevenire attività fraudolente e individuare anomalie di processo.

7. **Evoluzione e Personalizzazione dei Servizi in funzione della
   customer experience**

   Per intercettare al meglio le esigenze e il livello di soddisfazione
   degli utenti, è da anni utilizzata l'IA per realizzare un modello di
   classificazione, annotazione ed estrazione di entità ai fini
   dell'analisi dei feedback, e la loro classificazione utile ad
   indirizzare azioni evolutive o di personalizzazione dei servizi per
   specifiche necessità individuate in funzione delle classi di utenti
   (imprese, medici, cittadini).

Per implementare soluzioni di IA, è inoltre importante considerare anche
le implicazioni etiche, la sicurezza dei dati e la conformità normativa.
L'interazione con gli stakeholder e la formazione del personale sono
inoltre cruciali per garantire una transizione efficace verso l'utilizzo
dell'IA all'interno di un'organizzazione come INAIL. Su questi ultimi
aspetti è importante sottolineare come la collaborazione con istituti di
ricerca e università sia un fattore di accelerazione di innovazione e di
trasferimento tecnologico che permette costantemente all'Istituto di
meglio raggiungere i propri obiettivi. Su questo punto INAIL ha forti
connessioni ed esperienze, come quella relativa al Rehab Technologies
Lab nato dall'accordo con l'Istituto Italiano di Tecnologia.

5.5.2. Progetti futuri
~~~~~~~~~~~~~~~~~~~~~~

L'INAIL, in linea con i suoi obiettivi strategici ed evolutivi, ha
definito nel suo futuro a breve e medio termine un percorso di
consolidamento, evoluzione ed arricchimento delle sue soluzioni di IA.

Il principale focus vede l'INAIL concentrato nel potenziamento,
attraverso una soluzione basata sulle tecnologie IA generativa
(attualmente in prototipazione), del *knowledge management*,
semplificando il processo di acquisizione, distribuzione e utilizzo
efficace delle conoscenze di una organizzazione. La sperimentazione in
corso si concentra su un sistema di ricerca avanzato che risponda a
domande fornite dagli utenti in relazione ad informazioni contenute sia
in specifici documenti in ambito Istituzionale (concordati e acquisiti
durante le attività di sperimentazione), sia all'interno del portale web
`www.inail.it <http://www.inail.it>`__. La sperimentazione permette di
interrogare il perimetro informativo attraverso un *chatbot*, col quale
l'utente interagisce per ricercare le informazioni e dal quale riceve le
risposte alle domande formulate.

Rimanendo nell'ambito della gestione del patrimonio informativo, è in
corso la sperimentazione di un prototipo di *legal AI discovery* per
analizzare la documentazione legale. Il sistema permette
l'indicizzazione e una migliore consultazione delle informazioni e della
documentazione, fornendo un'esperienza avanzata di ricerca su documenti
e contenuti non strutturati. In particolare, viene data all'utente la
possibilità di ricercare per concetti, entità, parole semanticamente
simili, citazioni, riferimenti legislativi, ottenendo risultati accurati
e veloci, attraverso la capacità degli strumenti di IA di comprendere il
significato della frase o dei termini chiave inseriti.

Con riferimento all'applicazione dell'IA per il potenziamento
dell'operatività dell'INAIL, si ritiene utile citare una sperimentazione
da avviare a breve, dedicata alla realizzazione di un algoritmo di
Machine Learning volto a garantire l'efficientamento del modello di IT
Costing mediante la normalizzazione e classificazione dei dati. Nello
specifico, l'utilizzo di tecniche di *ML* e *text analytics* per
l'analisi delle iniziative è finalizzato al suggerimento automatico
della classificazione in termini di servizio, componente di servizio e
natura di costo.

Inoltre, nell'ottica di proseguire nel percorso di potenziamento del suo
modello di prossimità digitale verso l'utenza, sono già previsti e
parzialmente avviati specifici servizi attraverso tecnologie innovative
quali il metaverso, la realtà aumentata e l'IA generativa.

5.5.3. Organizzazione e processi di innovazione
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

L'INAIL ha da poco rinnovato la sua organizzazione e i suoi processi di
gestione delle innovazioni, al fine di adeguarsi alle richieste degli
utenti nella cosiddetta nuova normalità post pandemica, e alle rapide
evoluzioni delle tendenze tecnologiche. La necessità di innovare può
infatti essere dettata dall'evoluzione delle esigenze degli utenti ma
anche dal cambiamento dell'ecosistema circostante.

Per garantire il corretto focus sull'IA, e in generale sulle
innovazioni, interpretando correttamente le opportunità potenzialmente
derivanti dalle nuove tecnologie, l'INAIL si è organizzato per attivare
nei processi di gestione dell'innovazione figure specialistiche in
organico, o attraverso consulenze dei partner, che abbiano competenze
verticali e approfondite sui principali temi innovativi, con prioritario
focus sulle soluzioni IA. L'obiettivo di queste figure è quello di
svolgere un ruolo specialistico mirato nella valutazione di soluzioni
innovative in grado di rafforzare il ruolo di INAIL come istituzione
orientata all'innovazione per il business. Come illustrato nelle sezioni
precedenti, particolare attenzione è posta sulle soluzioni di IA,
nell'ottica di valorizzare l'eterogeneo patrimonio informativo
dell'INAIL e fornire all'utenza servizi sempre più completi ed evoluti.

L'obiettivo del rinnovato processo di *innovation management* è dunque
la creazione di valore per il business dell'INAIL attraverso
l'introduzione di soluzioni innovative, sfruttando le competenze
tecnologiche, di business e di design proprie degli specialisti
dell'Istituto, nonché dei suoi partner.

In questo senso, sono stati identificati diversi driver che hanno
guidato il rinnovamento dell'organizzazione e del processo di Innovation
Management:

-  Avvicinarsi progressivamente ad un modello maturo di "Open
   Innovation" che sia in grado di aumentare la ricettività
   dell'Istituto agli stimoli innovativi interni (idee e soluzioni
   proposte dalle Direzioni di business esterni) attraverso attività di
   Scouting Tecnologico.

-  Coinvolgere nel processo di innovazione competenze prevenienti da
   diverse aree funzionali per le rispettive competenze.

-  Supportare il processo con idonei strumenti (ad esempio la Scheda di
   valutazione Innovatività) in grado di fornire informazioni complete e
   standardizzate a tutti gli attori coinvolti nelle valutazioni,
   semplificando le fasi di analisi e di benchmark tra le soluzioni
   presentate.

-  Integrare la gestione delle innovazioni nel più ampio scenario
   operativo dell'INAIL, evitando sovrapposizioni con altri processi
   aziendali incaricati di raccogliere e analizzare le esigenze.

La nuova Organizzazione vede quindi tre attori principali, fra loro
complementari, a guidare il processo di Innovation Management:

-  CIT: Struttura dedicata alla Consulenza e Innovazione Tecnologica,
   composta da specialisti in campo Innovation e nuovi trend
   tecnologici.

-  Innovation Team: Team con specifiche competenze verticali che vengono
   costituiti ad hoc in funzione delle soluzioni innovative da valutare.

-  Innovation Board: Comitato multidisciplinare composto da referenti
   delle diverse aree funzionai e, alternativamente, da ulteriori
   partecipanti opzionali sulla base di specifiche esigenze o tematiche.

L'Innovation Board ha il compito di:

-  presidiare la governance dell'innovazione.

-  promuovere e definire gli indirizzi strategici e le linee guida di
   innovazione.

-  valutare la coerenza con gli indirizzi strategici e la fattibilità
   delle iniziative proposte, attraverso gli strumenti organizzativi e
   tecnici più opportuni (Innovation team, Proof of Concept, Progetti
   pilota, …).

5.5.4. Governance dei dati e dell'IA
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Nella sezione precedente sono descritti i processi e l'organizzazione
che INAIL ha instaurato per la gestione dell'innovazione.

Questo approccio è alla base di un percorso evolutivo che l'INAIL ha
individuato per la gestione strutturata dell'innovazione, specialmente
quella derivante dall'introduzione dell'IA. In questa sezione, quindi,
ci si focalizza sull'obiettivo dell'INAIL di adottare una più matura
strategia di *innovation management*, attraverso un percorso
incrementale. L'approccio incrementale è spesso utilizzato per gestire
la complessità del cambiamento e risulta particolarmente adeguato alla
gestione dei rischi associati all'implementazione di soluzioni di IA in
entità strutturate, perché permette flessibilità e risposta rapida ai
cambiamenti, con una *vision* di tipo evolutivo. Questa strategia si
colloca dunque in un quadro di lungo termine, dove vengono elaborati
piani d'azione dettagliati per conseguire gli obiettivi specifici che
l'INAIL si è proposto e che fungono da viatico per tutte le decisioni di
*business* che intraprende.

Il primo passo verso questo approccio passa anzitutto per l'adozione di
un'opportuna Governance dei dati a cui si integra la Governance dell'IA.
La priorità dell'INAIL è infatti quella di favorire un uso sostenibile
ed etico dei dati, e quindi di sviluppare sistemi di IA che siano non
solo perfettamente conformi alle normative vigenti e quelle imminenti
(cfr. paragrafo 3.1), ma che incarnino tutti i principi etici di
*Trustworthy AI* definiti *dall'High-Level Expert Group on AI*. La
visione a lungo termine è quindi quella di dotarsi di un framework di
governance dei dati e dell'IA che permetta ad INAIL di incrementare la
propria maturità nella gestione dei dati e dell'IA in modo sistemico,
etico e sostenibile.

Ci sono al momento specifici progetti che stanno definendo i principi
guida di gestione e un framework di governance dei dati a 360°, sulla
base delle best practice di mercato e in linea con l'approccio ESG
dell'INAIL e delle linee guida delle istituzioni europee. La definizione
dei principi guida detterà, chiaramente, una nuova linea per i processi
di sviluppo di sistemi e applicativi di IA nell'Istituto, con una presa
in carico dell'interno ciclo di vita degli stessi. L'impegno dell'INAIL
verso questa direzione è di lungo corso: in passato, infatti, INAIL si è
già dotata di un primo framework di Governance delle soluzioni di IA,
che standardizza la pipeline di sviluppo di soluzioni di IA e identifica
dei punti di controllo e delle azioni dettate da tali principi etici.
Questo approccio verrà ulteriormente integrato dalle attività relative
alla governance dei dati e dell'IA attualmente in corso, considerando
anche l'imminente approvazione del Regolamento AI Act (COM/2021/206
final), sul quale è stato raggiunto un accordo provvisorio lo scorso 9
Dicembre 2023 che risulta prodromico all'approvazione del Regolamento
stesso. Si terrà inoltre conto anche delle evoluzioni in ambito di IA
generativa.

L'istituzione del framework verrà necessariamente accompagnata da azioni
di formazione sui dipendenti con lo scopo di creare e diffondere una
aggiornata cultura del dato e un'appropriata conoscenza delle tematiche
di *data & AI ethics*. Data la visione a lungo termine di adozione
"diffusa" dell'IA, è fondamentale che tutti i dipendenti siano
adeguatamente preparati a lavorare in modo responsabile ed etico, sia
per aderire alle normative in vigore che per rappresentare un modello
virtuoso all'interno del panorama europeo e nazionale. È stato già
effettuato un primo inventario di competenze, che si ispira al
*Syllabus* e a *e-CF*, i due framework principali adottati nelle PA
italiane che evidenziano le competenze più importanti di chi si occupa
di gestione del dato a vario titolo.

Sulla base di questa premessa, saranno definiti nel dettaglio gli
elementi del modello organizzativo di governance attraverso un progetto
che contempla la creazione di ruoli specifici da inserire
nell'organigramma dell'Istituto. A tali ruoli si affiancheranno figure
specializzate in governance ed etica dell'IA. Grazie a queste nuove
designazioni, sarà possibile delineare chiaramente diritti e
responsabilità in relazione ai dati e all'IA. Ciò consentirà all'INAIL
di gestire in modo strutturato e organico l'intero ciclo di vita
dell'IA.

Difatti, l'approccio incrementale prevede anche che si definiscano
adeguati KPI per valutare la performance delle applicazioni e dei
sistemi di IA, al fine di correggere eventuali cause di rischio e
mantenere ogni sistema conforme ai principi etici e alla conformità
normativa (su questo punto, cfr. approfondimento in paragrafo 3.1). La
valutazione della performance va attuata secondo specifici obiettivi,
elaborati anche di accordo con i numerosi fornitori presenti
nell'Istituto, per poter assicurare un congruo *follow-up* al lancio
dell'applicativo sia dal punto di vista funzionale/di business che
infrastrutturale, tecnico e di sicurezza. Questo è quanto mai importante
data la necessità di indirizzare, anche per questioni di *compliance*,
eventuali rischi causati dalle applicazioni di IA, che possono
manifestarsi sia al lancio di nuovi sistemi, che per cambiamenti
legislativi futuri. È necessario, quindi, un monitoraggio continuo che
valuti l'efficacia della governance e introduca miglioramenti,
garantendo così un adeguato risk management.

L'implementazione progressiva di questi step di processo e l'interazione
del framework di data governance e governance dell'IA sono al centro di
specifiche raccomandazioni elaborate all'interno di un progetto su *ESG
e sostenibilità*, che si sta occupando proprio di analizzare i processi
dell'INAIL al fine di orientarli verso un iter etico e sostenibile.

La necessità di adottare un approccio evolutivo incrementale diventa
particolarmente urgente e rilevante, soprattutto considerando
l'imminente entrata in vigore dell'AI Act. In virtù di quest'ultimo,
l'INAIL sarà chiamato a conformarsi non solo a nuove normative di
conformità, ma anche a nuovi metodi di gestione. La necessità di attuare
un tale processo evolutivo, però, non viene solo dall'esigenza
legislativa e di *compliance*, ma anche dal ruolo e dalla responsabilità
sociale che l'INAIL assolve nell'ecosistema italiano. Infatti,
contrariamente a quanto avviene in una società o organizzazione privata,
il ruolo di una pubblica amministrazione è quello di affrontare certe
tematiche con un riguardo maggiore verso i cittadini e i loro diritti,
con l'obiettivo di rafforzare il rapporto di fiducia con essi, andando
oltre ai requisiti minimi di *compliance* ai dettami legislativi.

5.5.5. Come affrontare l'AI Act
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

L'impatto più tangibile e articolato dell'AI Act sarà quello relativo
alla conformità normativa. In quanto fornitore, l'INAIL dovrà adeguarsi
ai requisiti imposti dalla nuova legge, prevedendo di adeguare i propri
sistemi - sviluppati internamente o con il supporto di partner - alle
nuove norme, specie per quanto riguarda i sistemi classificati come ad
alto rischio secondo la stratificazione prevista dal Regolamento
Europeo. La nostra mappatura delle applicazioni rileva che al momento
non ci sono sistemi di IA che rientrano in questa categoria, ma è bene
che l'Istituto tenga ben presenti gli obblighi che essi comportano e che
si monitori nel tempo la rischiosità delle proprie applicazioni e le
evoluzioni delle prescrizioni regolamentari. Su questo punto, si prevede
l'istituzione di un catalogo delle applicazioni che permetta un
monitoraggio centralizzato e continuato nel tempo, supportando così la
*compliance* dell'Istituto. La centralizzazione del catalogo permetterà
di agire in modo tempestivo e uniforme qualora dovessero esserci
modifiche alla regolamentazione, e di verificare che le applicazioni in
utilizzo siano o meno ad alto rischio. Inoltre, si faciliterebbe il
monitoraggio del rispetto dei requisiti regolamentari, come per esempio
il tipo di dati utilizzato, se l'applicazione utilizza sistemi di
identificazione biometrica remota, se regola l'accesso ad alcuni
prestazioni e servizi pubblici e servizi privati essenziali, oppure se
interagisce in modo diretto con gli esseri umani e di conseguenza è
necessario che la persona ne sia informata.

Considerando l'INAIL sia nel ruolo di utente che di fornitore di
soluzioni di IA, la conformità normativa sarà di fondamentale importanza
e si prevede lo sviluppo di specifiche checklist per facilitare
l'identificazione del livello di rischio rispetto all'AI Act e dei
conseguenti requisiti normativi. In questo sarà fondamentale la
collaborazione tra gli uffici che sviluppano o utilizzano applicazioni
di IA e le funzioni di controllo. Inoltre, come precedentemente
anticipato (cfr. Paragrafo 3) si dovranno prevedere sistemi di
monitoraggio delle performance dei sistemi di IA in utilizzo al fine di
assicurarsi, durante tutto il ciclo di vita dei sistemi, il rispetto dei
requisiti come affidabilità, non discriminazione, accuratezza,
robustezza e cybersicurezza, sorveglianza umana e qualità dei dati.
Infatti, tutti fornitori e gli utenti di sistemi di IA ad alto rischio
devono garantire la conformità ai requisiti sopracitati, ma soprattutto
disporre di un sistema di gestione della qualità e del rischio, che in
caso di applicazioni ad alto rischio, avvii un processo di monitoraggio
iterativo e continuo. Anche i dataset utilizzati devono essere
pertinenti, rappresentativi, esenti da errori e completi. Come già
sottolineato, l'INAIL sta valutando quali dei requisiti obbligatori per
le applicazioni di IA ad alto rischio siano comunque da implementare per
assicurare un livello di governance maggiore che vada oltre la
*compliance* ma verso un rapporto più di fiducia con i propri utenti e i
cittadini.

Sul tema di IA generativa, data la forte spinta innovativa e la volontà
di investire in tali tecnologie, già in uso all'interno dell'Istituto,
INAIL vuole strutturarsi fin da ora per gestire adeguatamente questo
processo di adozione al fine di assicurare i giusti livelli di
supervisione, controllo e rispetto dei requisiti non solo legali, ma
etici. Infatti, l'IA generativa pone diversi rischi, tra cui risultati
*biased* e discriminatori, che generano preoccupazioni sulla sicurezza
delle informazioni e la loro affidabilità. Il meccanismo di governo di
questi sistemi non è ancora definito, ma al momento si prevede
sicuramente l'adozione di Codici di Condotta e *model cards*, che
includano le informazioni rilevanti per comprendere il funzionamento del
modello, le sue capacità e i suoi limiti. Quando l'AI Act sarà in
vigore, questo comporterà principalmente un controllo sui propri
fornitori e la corretta interazione con l'AI Office europeo che verrà
istituito.

Il framework di governance dei dati e dell'IA che è in corso di
definizione cercherà di indirizzare tutti questi requisiti
regolamentari, ma cercherà inoltre di formalizzare una governance che
vada anche oltre alla *compliance*. In questo senso, il framework
permetterà di migliorare l'efficienza e l'efficacia delle soluzioni di
IA in adozione nell'Istituto e di implementare anche i requisiti etici
di cui l'AI Act è portatore.

L'adozione dell'AI Act rappresenterà un nuovo corso per l'INAIL, che non
potrà soffermarsi solo sulle necessità di *compliance*, seppur centrali.
Le pubbliche amministrazioni, infatti sono spinte ad andare oltre la
*compliance* dato il ruolo sociale che esercitano e alla necessità di
rafforzare il rapporto di fiducia con i cittadini. L'adozione di un
*framework* di *governance* a 360° garantirà ad INAIL di andare oltre i
dettami legislativi verso una visione etica e responsabile della
tecnologia, come richiesto ad un attore pubblico e socialmente rilevante
quale l'INAIL.

Il complesso iter di revisione di processi e prassi interne che l'INAIL
dovrà intraprendere per raggiungere gli ambiziosi obiettivi fin qui
esposti, sono al centro di una serie di raccomandazioni che, come
precedentemente anticipato, indirizzeranno l'implementazione del
cambiamento da un punto di vista organizzativo e culturale. Le
raccomandazioni terranno in considerazione i diversi gradi di maturità
dei processi già presenti all'interno dell'Istituto e prevederanno, se
necessario, lo *scouting* di strumenti tecnologici a supporto delle
nuove metodologie da integrare nei processi esistenti.

5.6. L'esperienza di INPS
-------------------------

L'INPS ha maturato una significativa esperienza in materia di
Intelligenza Artificiale (IA) e IA generativa. Le dimostrazioni pratiche
fornite dall'INPS hanno illustrato in modo tangibile i miglioramenti che
l'implementazione di questa tecnologia può apportare nel settore
pubblico.

Di seguito si riportano gli elementi fondamentali di alcuni dei
principali progetti ideati e implementati dall'INPS con l'obiettivo di
potenziare i servizi offerti all'utenza mediante l'impiego
dell'intelligenza artificiale.

5.6.1. I progetti
~~~~~~~~~~~~~~~~~

5.6.1.1. Classificazione e smistamento automatico della Posta Elettronica Certificata (PEC)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Si prevede che l'INPS riceverà nel 2023 un volume di oltre 6 milioni di
PEC, con una media superiore a 16.000 PEC al giorno. La corretta
individuazione dell'argomento trattato e la successiva assegnazione
all'ufficio competente richiederebbero un notevole impiego di risorse
umane, con un elevato numero di addetti dedicati esclusivamente allo
smistamento delle PEC. La soluzione sviluppata dall'INPS, basata su IA,
consente uno smistamento automatizzato e rapido delle PEC in arrivo,
senza richiedere l'intervento umano.

Questo processo permette all'INPS di liberare circa 40.000 ore di lavoro
annue, che possono essere impiegate per compiti di diretto servizio
all'utenza, compresa la lavorazione della voluminosa mole di
comunicazioni in ingresso. Con questo progetto l'INPS ha ricevuto un
prestigioso riconoscimento da parte di IRCAI, Centro di Ricerca
Internazionale per l'Intelligenza Artificiale sotto l'egida UNESCO,
posizionandosi tra i 10 migliori progetti mondiali in ambito di
Intelligenza Artificiale che supportano i 17 SDGs (Obiettivi di Sviluppo
Sostenibile) dell'ONU.

5.6.1.2. Gestione delle richieste al Customer Service
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Il progetto, in fase di rilascio previsto per il primo trimestre del
2024, è rivolto alla gestione ottimizzata delle richieste web che
vengono rivolte al *Customer Service* di INPS, il quale riceve circa 2,5
milioni di richieste l'anno. Attualmente, ogni istanza viene presa in
carico da un operatore di primo livello, il quale è in grado di
rispondere correttamente nel 40% dei casi. Nel restante 60%, l'operatore
deve inoltrare l'istanza ad un operatore specializzato nell'area della
richiesta ricevuta, definito di secondo livello.

La soluzione basata su IA che INPS ha sviluppato, consente di
indirizzare correttamente oltre un terzo delle richieste direttamente
all'operatore di secondo livello, consentendo un notevole risparmio di
lavoro umano da parte dell'operatore di primo livello. L'INPS è stato
selezionato come vincitore con il progetto in questione durante il
convegno "Premi Agenda Digitale" che si è tenuto a gennaio 2023,
dedicato alle PA, PMI e startup che si sono distinte per progetti di
digitalizzazione in ambito pubblico.

5.6.1.3. Assistente virtuale
^^^^^^^^^^^^^^^^^^^^^^^^^^^^

INPS sta utilizzando tecnologie di intelligenza artificiale al fine di
migliorare drasticamente le capacità dell'Assistente Virtuale unificato
dell'INPS, che sarà presto in grado di dare una risposta automatizzata
all'utente vagliando una vasta mole di dati di pubblico dominio, tra cui
normativa, messaggi e circolari dell'INPS, al fine di fornire una
risposta immediata ed automatizzata.

A marzo 2022 INPS ha avviato un progetto PNRR denominato *Chatbot*
intelligente conclusosi a febbraio 2023 con il rilascio in produzione di
un assistente virtuale su Portale internet di tipo generalista.

Attualmente l'architettura di riferimento dell'Assistente Virtuale unico
è su due livelli:

-  **Masterbot generalista**, con l'obiettivo di:

   -  Fornire un rapido accesso ai *chatbot* verticali (carosello oppure
      *routing* / *integration*);

   -  Guidare il cittadino alla prestazione / area di prestazione di
      interesse, se possibile rispondendo già alla domanda, utilizzando
      AI generativa per classificare la domanda;

-  **Skillbot specializzato** (*chatbot* verticale) con l'obiettivo di
   rispondere alla domanda puntualmente.

L'architettura su due livelli ha già permesso l'indirizzamento delle
nuove chatbot verticali su servizi comuni, nonché il riuso delle chatbot
già sviluppate in INPS, adottando apposite linee guida di integrazione.

A marzo 2023 INPS ha avviato una nuova iniziativa legata all'AI di tipo
generativo, tutt'ora in corso. Una prima sperimentazione è stata già
rilasciata ad agosto 2023 (durata 4 settimane) per migliorare
l'esperienza utente sul motore di ricerca (scenario 1) e per rispondere
a domande utente riguardanti la prestazione "opzione donna" (scenario 2
- verticale). Successivamente è stata rilasciato in novembre 2023 un
secondo scenario verticale, per la prestazione "Supporto per la
formazione ed il Lavoro".

La soluzione già realizzata con AI di tipo generativo ha prodotto un
cambio di paradigma non solo nell'esperienza utente ma anche nel
processo di produzione delle chatbot, mettendo in evidenza l'efficienza
di un modello scalabile che permette, a valle dell'acquisizione dei
contenuti validati dagli SME, strutturati seguendo apposite linee guida
fornite dalla DC Informatica alle altre DC di prodotto, l'esecuzione di
pochi passaggi per la configurazione applicativa e la pubblicazione
dello "Skillbot specializzato" all'interno del Portale internet di INPS.
Attività chiave sono il prompt engineering di tuning ed i test utente.

5.6.1.4. Altri progetti
^^^^^^^^^^^^^^^^^^^^^^^

Oltre ai progetti menzionati sopra, INPS si sta specializzando anche nel
portare avanti iniziative di AI nell'ambito contenzioso e legale. In
queto contesto, è da evidenziare che allo stato attuale le comunicazioni
non strutturate in ambito legale pervengono all'INPS in forma digitale
tramite PEC. I dipendenti di INPS applicano metadati a queste
comunicazioni inserendo nell'applicativo di interesse le informazioni di
contesto necessarie (parti in causa, tribunale, ecc.) presenti nella
documentazione specifica. In questo contesto, il progetto ha lo scopo di
utilizzare un sistema di Intelligenza Artificiale in grado di elaborare
le comunicazioni digitali estraendo automaticamente le informazioni di
contesto dai documenti di interesse, in modo da ridurre notevolmente il
tempo richiesto per l'inserimento dei dati e rendere più efficiente il
processo di data-entry.

Un progetto simile, relativo sempre all'estrazione dei dati dai
documenti è "Smart Prof" per il quale l'INPS prevede di efficientare i
processi di pagamento per il bonus asilo nido.

5.6.2. Le sfide legate all'IA generativa
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Grazie alla diffusione ed alla notorietà delle tecnologie legate
all'intelligenza artificiale generativa il periodo attuale emerge come
uno dei più dinamici e rivoluzionari nel settore specifico relativo
all'Intelligenza Artificiale. L'ampia diffusione ed applicabilità delle
soluzioni basate sull'intelligenza artificiale generativa hanno reso
immediatamente evidenti (su vasta scala) i vantaggi che tale tecnologia
può apportare nell'immediato e nella quotidianità delle persone, data la
notevole semplicità di utilizzo.

La corsa verso gli "human-like-bot" ha generato un notevole impatto in
tutti i settori sia privato che pubblici. Infatti, la ricerca su questi
modelli di intelligenza artificiale generativa continua a progredire,
portando a costanti evoluzioni ed aggiornamenti sulle architetture e sui
modelli coinvolti, noti come LLM (Large Language Model).

In particolare, sono già emersi (e continuano a progredire) anche LLM
Open Source. Questo consente di evitare la dipendenza da prodotti sì
avanzati ma chiusi e controllati da compagnie private straniere, e allo
stesso tempo permette di sfruttare al meglio le competenze delle
comunità globali.

Allo stato attuale esistono due modalità per poter usufruire
dell'intelligenza artificiale generativa: affidarsi a un fornitore cloud
oppure adottare un modello "Open Source" su un'infrastruttura interna
("on premise"). L'aspetto vincolante, in questa scelta, è la complessità
di tali modelli, i quali necessitano di infrastrutture ad elevate
prestazioni, fattore che giustifica il ricorso a modelli basati su cloud

Tuttavia, l'utilizzo dei modelli cloud presenta un problema di fondo:
essi sono continuamente addestrati e migliorati senza alcun controllo da
parte dell'utilizzatore, compromettendo la chiarezza nell'utilizzo dei
dati nel processo di addestramento/training, in contrasto con il
concetto di trasparenza e spiegabilità sostenuto dall'AI Act.

In aggiunta, l'utilizzo dei modelli cloud pone un interrogativo
importante sulla gestione dei dati sensibili, come quelli presenti nella
pubblica amministrazione e in enti governativi. A prescindere dalle
rassicurazioni legali, fornire tali dati ai cloud vendor pone seri
rischi presenti e futuri riguardo la salvaguardia della privacy del
cittadino e la confidenzialità dei dati.

5.6.3. Lezioni apprese
~~~~~~~~~~~~~~~~~~~~~~

L'esperienza di INPS fornisce alcuni punti di attenzione ed elementi di
riflessione per tutte le pubbliche amministrazioni in procinto di
adottare soluzione basate su intelligenza artificiale.

-  La scelta del modello di intelligenza artificiale è determinante per
   ottenere risultati in linea con le specifiche esigenze. La Pubblica
   Amministrazione dovrebbe valutare:

   -  modelli predittivi non linguistici (e.g. Machine learning
      *supervised o unsupervised*);

   -  modelli linguistici per la comprensione ed il confronto di
      contenuti;

   -  modelli linguistici per la generazione di contenuti.

Le tre categorie di modelli hanno costi, complessità e maturità diverse.

-  Le pubbliche amministrazioni dovrebbero prediligere modelli
   predittivi non linguistici quando i dati sono strutturati ed i
   predittori della risposta sono un numero molto elevato e di tipologia
   eterogenea (e.g., controlli antifrode); dovrebbe invece prediligere
   modelli linguistici per la comprensione ed il confronto di contenuti
   in scenari di disambiguazione (e.g., instradamento di un problema,
   classificazione di un testo, estrazione di testo da un documento);
   infine, i modelli linguistici per la generazione di contenuti in
   scenari di conversazione con l'utenza (e.g., assistenti virtuali) e
   nel supporto decisionale (e.g., raccomandazione). Alcuni algoritmi
   potrebbero essere più indicati di altri in base al ruolo nella
   soluzione, di conseguenza è opportuno valutare il livello di
   personalizzazione e di flessibilità fin dall'inizio.

-  Le pubbliche amministrazioni che intendono realizzare servizi di tipo
   chat/voice bot basati su intelligenza artificiale di tipo generativo
   devono prevedere un processo di analisi documentale ed
   un'infrastruttura di raccolta dei documenti (base di conoscenza), che
   permetta di governarne in modo efficace, anche sotto il profilo
   organizzativo, l'acquisizione, l'aggiornamento, la "metadatazione" e
   la validazione dei contenuti, coinvolgendo gli esperti della materia
   in ogni fase del ciclo di vita del modello "linguistico" utilizzato.

-  Le pubbliche amministrazioni che intendono avvalersi di intelligenza
   artificiale di tipo generativo dovranno porre attenzione alla qualità
   dei contenuti, per ridurre al minimo il fattore aleatorio di
   "interpretabilità" del significato dei testi, mai del tutto
   neutralizzabile, l'effetto di "dispersione" dell'informazione,
   dipendente dalla ridondanza dei concetti, l'uso di termini e sigle
   tipiche di un contesto tematico, rischiose se non ben inquadrate.
   L'effettiva presenza delle informazioni all'interno delle fonti è
   determinante per la generazione di una risposta; la presenza di
   terminologia specialistica o assente dal vocabolario (es. acronimi,
   neologismi, forme letterarie particolarmente articolate o inusuali)
   va ridotta o adeguatamente tradotta in linguaggio aderente ai modelli
   linguistici su cui è addestrata l'intelligenza artificiale di tipo
   generativo (foundation model). Per fare un esempio, se
   l'addestramento del modello è stato eseguito su documenti dove il
   termine "pensione" è legato alle rendite da polizza ed il contesto di
   utilizzo del modello è la Previdenza Sociale risulterà di
   particolarmente importante "correggere" nella soluzione (tipicamente
   nel prompt engineering, durante la fase di tuning) come il termine
   "pensione" va utilizzato.

-  I contenuti utilizzati dall'intelligenza artificiale di tipo
   generativo devono essere autorizzati da fonti autorevoli e
   competenti, ovvero deve essere esplicitamente inibita (tipicamente
   nel *prompt engineering*) ogni forma di "creatività" cui
   tendenzialmente mirano i modelli linguistici di tipo generativo,
   poiché questi hanno, in generale, l'obiettivo di ricostruire un senso
   compiuto e realistico di una conversazione, non quello di riportare
   la realtà dei fatti. Opportuno, inoltre, che le fonti siano riportate
   direttamente nella risposta fornita dalla chatbot/voice bot , oppure
   siano tracciate dietro le quinte, e nel caso recuperabili.

-  Le Pubbliche Amministrazioni che intendono avvalersi di intelligenza
   artificiale di tipo generativo devono costruire un proprio Framework
   di Valutazione della bontà delle "Risposte", basato su un numero
   significativo di "Domande", suddivise per tematica, ed un numero di
   indicatori puntuali di valutazione di tipo sia qualitativo che
   quantitativo. Parte di tale Framework di Valutazione è il meccanismo
   attraverso cui sono raccolti i feedback dal Cittadino, utili a
   stabilire il grado di affidabilità dei risultati ed a migliorare il
   modello.

-  Per ridurre il rischio di lock-in dai servizi offerti dal mercato è
   raccomandato che la soluzione adottata sia basata su modelli aperti e
   componenti intercambiabili e interoperabili, nello specifico è
   raccomandato adottare modelli più maturi e meno costosi per
   realizzare le componenti della soluzione più stabili e semplici di
   funzionamento, quindi isolare le componenti della soluzione sulle
   quali confrontare tra loro modelli diversi, applicando la
   competizione tra tecnologie sui compiti più complessi e sfidanti,
   coinvolgendo anche produttori di AI generativa di nicchia.

-  Nel presentare al Cittadino una soluzione di Assistente Virtuale
   basata su intelligenza artificiale di tipo generativo il Cittadino
   deve essere informato su alcuni aspetti:

   -  Il Cittadino deve essere informato che la qualità della risposta
      dipende dalla qualità della sua domanda. Domande corte e poco
      contestualizzate metteranno in difficoltà l'assistente virtuale
      che, in prima battuta, ha necessità di recuperare il contesto.

   -  Il Cittadino deve essere informato che le risposte potrebbero
      contenere errori e, lì dove si siano già raccolti dei feedback,
      fornendo la percentuale statistica.

-  Nel processo di interazione tra Cittadino e Assistente Virtuale
   basato su intelligenza artificiale di tipo generativo deve essere
   applicata una strategia di comunicazione che permetta al Cittadino di
   interloquire per avere risposte personalizzate, usando un contesto di
   risposta che, nel corso della conversazione, deve potersi arricchire
   di informazioni. Rispetto ai chat/voice bot tradizionali, che sono
   basati su flussi di dialogo "rigidi" (what if) in questo caso sono
   necessarie metodologie per orientare il dialogo prevedendo punti di
   consolidamento (congestion), dove può essere l'Assistente virtuale a
   porre domande e suggerimenti.

5.7. L'esperienza di ISTAT
--------------------------

ISTAT ha attivato diversi progetti per esplorare le potenzialità dell'IA
nell'ambito delle proprie attività istituzionali.

Da anni ISTAT utilizza tecniche di IA attraverso l'uso delle ontologie
per modellare i dati. Infatti, il linguaggio logico delle ontologie è in
grado di abilitare il "ragionamento automatico" (reasoner) per il
controllo della qualità dei dati, recuperando eventuali incoerenze sui
dati e fornendo nuove informazioni non direttamente ottenibili dalle
analisi dei dati stessi.

Recentemente, ISTAT sta esplorando una possibile soluzione attraverso
l'uso di algoritmi di AI generativa per produrre ontologie partendo da
una descrizione in linguaggio naturale del contesto semantico che si
vuole modellare. La necessaria interazione con gli specialisti consente
sia l'addestramento degli algoritmi che il miglioramento della qualità
della modellazione. Una possibile applicazione di tali tecniche
generative può essere utilizzata nell'ambito della gestione dei dati
delle Pubbliche Amministrazioni, per rendere i dati amministrativi
interoperabili attraverso le tecniche del semantic web, ottimizzando
l'impegno - di risorse con competenze specialistiche elevate.

Altri casi di studio, in corso di verifiche, riguardano la produzione
dei dati statistici, dalla loro raccolta alla diffusione.

Nell'ambito della raccolta dati si ipotizza l'utilizzo di un assistente
virtuale per supportare gli utenti nella compilazione dei questionari di
indagine.

Per la fase di diffusione dei dati statistici sono allo studio diversi
casi d'uso:

-  Utilizzo di una chat bot per aiutare gli utenti a trovare, tra i
   documenti e i comunicati stampa disponibili sul sito istituzionale,
   le informazioni statistiche desiderate.

-  Abilitazione della ricerca semantica sui contenuti del sito
   istituzionale

-  Assistente virtuale per rispondere alle richieste inviate dagli
   utenti al Contact Centre

-  Utilizzo di IA per la creazione di query per l'interrogazione di
   repository (DB relazionali, NoSQL, asset semantici, Linked Open Data)
   utilizzando il linguaggio naturale.

Infine, anche per gli utenti interni si intende sperimentare l'utilizzo
di IA generativa per la richiesta di informazioni su procedure
amministrative interne (delibere, regolamentazioni, compilazione di
modulistica per il personale).
